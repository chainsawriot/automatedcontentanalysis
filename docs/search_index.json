[
["index.html", "Automated Content Analysis 1 Prerequisites", " Automated Content Analysis Chung-hong Chan 2020-01-26 1 Prerequisites The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. "],
["intro.html", "2 Introduction", " 2 Introduction When I was a high-school student, biology was my favourite subject. My bigger brother used the same textbook but an outdated edition and thus I didn’t need to buy it. Meanwhile my classmates were using the newer edition, I enjoyed reading the old edition from my brother. That book had over 1000 pages and was completely in black and white. Students and teachers alike spotted me reading that book almost all the time at the corner of the spectator stand. "],
["the-whole-game.html", "3 The whole game", " 3 The whole game We are going to use an example to illustrate the whole process of a typical automated content analysis scenario. In this example, we start with a simple research question or hypothesis. Let’s say I want to reproduce a very famous analysis of Donald Trump’s tweets. This example is very well-known in the data science scene, probably because one of the authors of the tidytext package used this example to demonstrate the power of his package (and made him on the television). The research question is very simple: are tweets from Donald Trump’s twitter account tweeted using an iPhone less angry than those tweeted using an Android phone? There are many elements to unpack in the above paragraph. The utmost important issue is that, all automated content analysis project should have hypotheses to test or research questions to answer. If a project without hypotheses or research questions, it can hardly be called automated content analysis (see Chapter 2 for longer discussion). Then we can think of the context we are interested to analyze (Donald Trump and his Twitter), operationalization of variables (what is angry?), data collection plan and data analysis strategy. In this book, however, we are not going to focus on 1) how to form hypotheses or research questions and 2) how to collect your (text) data. The reason for excluding the former is that, it needs to be supported by communication theories. As a book that is intented as an research methods book, it is probably a bit too much. For the latter, the exclusion of it is due to the fact that there are good papers and textbooks available. The book chapter by Liang &amp; Zhu (2017) is probably a good start. Simon Munzert et al (2015) ’s Automated Data Collection with R is an in-depth manual. In the companion website of this book, you can find the tweets from Donald Trump’s tweet account before he assumes duty as the president of the United States. The data looks like this: require(tidyverse) ## Loading required package: tidyverse ## ── Attaching packages ────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.2.1 ✔ purrr 0.3.3 ## ✔ tibble 2.1.3 ✔ dplyr 0.8.3 ## ✔ tidyr 0.8.3 ✔ stringr 1.4.0 ## ✔ readr 1.3.1 ✔ forcats 0.4.0 ## ── Conflicts ───────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() require(quanteda) ## Loading required package: quanteda ## Package version: 1.5.2 ## Parallel computing: 2 of 4 threads used. ## See https://quanteda.io for tutorials and examples. ## ## Attaching package: &#39;quanteda&#39; ## The following object is masked from &#39;package:utils&#39;: ## ## View require(rio) ## Loading required package: rio ## ## Attaching package: &#39;rio&#39; ## The following object is masked from &#39;package:quanteda&#39;: ## ## convert trump_tweets &lt;- import(&#39;./data/trump.json&#39;) %&gt;% as_tibble trump_tweets ## # A tibble: 17,936 x 7 ## source text created_at retweet_count favorite_count is_retweet id_str ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt; &lt;chr&gt; ## 1 Twitte… Heads… Mon Dec 3… 20519 74566 FALSE 10798… ## 2 Twitte… ....S… Mon Dec 3… 17027 63013 FALSE 10798… ## 3 Twitte… It’s … Mon Dec 3… 29355 125931 FALSE 10797… ## 4 Twitte… I’m i… Mon Dec 3… 30742 131151 FALSE 10797… ## 5 Twitte… I’m i… Mon Dec 3… 1123 4217 FALSE 10797… ## 6 Twitte… I am … Mon Dec 3… 25252 111582 FALSE 10797… ## 7 Twitte… I cam… Mon Dec 3… 21960 90883 FALSE 10797… ## 8 Twitte… .....… Mon Dec 3… 15081 72353 FALSE 10797… ## 9 Twitte… ...I … Mon Dec 3… 22000 100819 FALSE 10797… ## 10 Twitte… If an… Mon Dec 3… 17379 79095 FALSE 10797… ## # … with 17,926 more rows "],
["what-is-automated-content-analysis.html", "4 What is automated content analysis? 4.1 What is Content analysis 4.2 What get automated? 4.3 Best practices", " 4 What is automated content analysis? 4.1 What is Content analysis As a super express summary of Krippendorff and Neuendorf. But don’t do it like Leetaru! 4.2 What get automated? What the current literature says about ACA. 4.3 Best practices Validation Contrasting Confirmatory / exploratory Methodological transparency "],
["creating-gold-standard-validation.html", "5 Creating gold standard &amp; validation", " 5 Creating gold standard &amp; validation avocate a workflow of making gold standard first! "],
["typical-automated-content-analytic-methods.html", "6 Typical automated content analytic methods 6.1 dictionary-based method 6.2 topic-model", " 6 Typical automated content analytic methods 6.1 dictionary-based method how it works off-the-shelf creating domain specific one 6.1.1 validation suggestions 6.2 topic-model 6.2.1 validation daniel maier / Chang "],
["advance-topics.html", "7 Advance topics 7.1 bag-of-embeddings 7.2 semantic network 7.3 machine learning 7.4 multimodal analysis 7.5 crosslingual analysis", " 7 Advance topics 7.1 bag-of-embeddings 7.2 semantic network 7.3 machine learning 7.4 multimodal analysis 7.5 crosslingual analysis "],
["references.html", "References", " References "]
]
