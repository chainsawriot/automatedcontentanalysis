<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 The whole game | Automated Content Analysis</title>
  <meta name="description" content="Make automated content analysis uncool again!" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 The whole game | Automated Content Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Make automated content analysis uncool again!" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 The whole game | Automated Content Analysis" />
  
  <meta name="twitter:description" content="Make automated content analysis uncool again!" />
  

<meta name="author" content="Chung-hong Chan" />


<meta name="date" content="2020-01-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="intro.html"/>
<link rel="next" href="what-is-automated-content-analysis.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Automated Content Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a></li>
<li class="chapter" data-level="3" data-path="the-whole-game.html"><a href="the-whole-game.html"><i class="fa fa-check"></i><b>3</b> The whole game</a><ul>
<li class="chapter" data-level="3.1" data-path="the-whole-game.html"><a href="the-whole-game.html#analysing-trumps-tweets"><i class="fa fa-check"></i><b>3.1</b> Analysing Trump’s tweets</a></li>
<li class="chapter" data-level="3.2" data-path="the-whole-game.html"><a href="the-whole-game.html#an-express-summary-of-tidyverse"><i class="fa fa-check"></i><b>3.2</b> An express summary of tidyverse</a></li>
<li class="chapter" data-level="3.3" data-path="the-whole-game.html"><a href="the-whole-game.html#creating-ground-truth-data"><i class="fa fa-check"></i><b>3.3</b> Creating ground truth data</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="what-is-automated-content-analysis.html"><a href="what-is-automated-content-analysis.html"><i class="fa fa-check"></i><b>4</b> What is automated content analysis?</a><ul>
<li class="chapter" data-level="4.1" data-path="what-is-automated-content-analysis.html"><a href="what-is-automated-content-analysis.html#what-is-content-analysis"><i class="fa fa-check"></i><b>4.1</b> What is Content analysis</a></li>
<li class="chapter" data-level="4.2" data-path="what-is-automated-content-analysis.html"><a href="what-is-automated-content-analysis.html#what-gets-automated"><i class="fa fa-check"></i><b>4.2</b> What gets automated?</a></li>
<li class="chapter" data-level="4.3" data-path="what-is-automated-content-analysis.html"><a href="what-is-automated-content-analysis.html#best-practices"><i class="fa fa-check"></i><b>4.3</b> Best practices</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="creating-gold-standard-validation.html"><a href="creating-gold-standard-validation.html"><i class="fa fa-check"></i><b>5</b> Creating gold standard &amp; validation</a></li>
<li class="chapter" data-level="6" data-path="typical-automated-content-analytic-methods.html"><a href="typical-automated-content-analytic-methods.html"><i class="fa fa-check"></i><b>6</b> Typical automated content analytic methods</a><ul>
<li class="chapter" data-level="6.1" data-path="typical-automated-content-analytic-methods.html"><a href="typical-automated-content-analytic-methods.html#dictionary-based-method"><i class="fa fa-check"></i><b>6.1</b> dictionary-based method</a><ul>
<li class="chapter" data-level="6.1.1" data-path="typical-automated-content-analytic-methods.html"><a href="typical-automated-content-analytic-methods.html#validation"><i class="fa fa-check"></i><b>6.1.1</b> validation</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="typical-automated-content-analytic-methods.html"><a href="typical-automated-content-analytic-methods.html#topic-model"><i class="fa fa-check"></i><b>6.2</b> topic-model</a><ul>
<li class="chapter" data-level="6.2.1" data-path="typical-automated-content-analytic-methods.html"><a href="typical-automated-content-analytic-methods.html#validation-1"><i class="fa fa-check"></i><b>6.2.1</b> validation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="advance-topics.html"><a href="advance-topics.html"><i class="fa fa-check"></i><b>7</b> Advance topics</a><ul>
<li class="chapter" data-level="7.1" data-path="advance-topics.html"><a href="advance-topics.html#bag-of-embeddings"><i class="fa fa-check"></i><b>7.1</b> bag-of-embeddings</a></li>
<li class="chapter" data-level="7.2" data-path="advance-topics.html"><a href="advance-topics.html#semantic-network"><i class="fa fa-check"></i><b>7.2</b> semantic network</a></li>
<li class="chapter" data-level="7.3" data-path="advance-topics.html"><a href="advance-topics.html#machine-learning"><i class="fa fa-check"></i><b>7.3</b> machine learning</a></li>
<li class="chapter" data-level="7.4" data-path="advance-topics.html"><a href="advance-topics.html#multimodal-analysis"><i class="fa fa-check"></i><b>7.4</b> multimodal analysis</a></li>
<li class="chapter" data-level="7.5" data-path="advance-topics.html"><a href="advance-topics.html#crosslingual-analysis"><i class="fa fa-check"></i><b>7.5</b> crosslingual analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Automated Content Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="the-whole-game" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> The whole game</h1>
<div id="analysing-trumps-tweets" class="section level2">
<h2><span class="header-section-number">3.1</span> Analysing Trump’s tweets</h2>
<p>We are going to use an example to illustrate the whole process of a typical automated content analysis scenario. In this example, we start with a simple research question or hypothesis. Let’s say I want to reproduce a very <a href="http://varianceexplained.org/r/trump-tweets/">famous analysis of Donald Trump’s tweets</a>. This example is very well-known in the data science world, probably because one of the authors of the tidytext package used this example to demonstrate the power of his package (and made him on the <a href="https://www.youtube.com/watch?v=vD11aSCpF4s&amp;feature=share">television</a>). The research question is very simple: are tweets from Donald Trump’s twitter account tweeted using an iPhone more positive than those tweeted using an Android phone?</p>
<p>There are many elements to unpack from the above paragraph, but the above paragraph illustrates how data scientists and automated content analysis practitioners approach the problem differently. The utmost important element is: All automated content analysis project must have hypotheses to test or research questions to answer. If a project without hypotheses or research questions, it can hardly be called automated content analysis (see Chapter 2 for longer discussion). We also need to specify the context we are interested to analyze (Donald Trump and his Twitter). Later on, we need to think about the operationalization of variables (<em>what is positive?</em>), data collection plan and data analysis strategy.</p>
<p>In this book, however, we are not going to focus on 1) how to form hypotheses or research questions and 2) how to collect your (text) data. The reason for excluding the former is simple: It needs to be supported by communication theories. As a book that is intented as an research methods book, it is probably a bit too much to ask.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> For the latter, the exclusion of it is due to the fact that there are good papers and textbooks available. The book chapter by <span class="citation">Liang and Zhu (<a href="#ref-liang2017">2017</a>)</span> is probably a good start. <span class="citation">Munzert et al. (<a href="#ref-munzert2014">2014</a>)</span> ’s <em>Automated Data Collection with R</em> is an in-depth manual.</p>
<p>At this point, you should probably go to preregister the hypotheses of this automated content analysis project. And then you should study the rtweet package by the wonderful Michael Kearney. Let’s suppose your data is now magically available. In the companion website of this book, you can find the data file with tweets from Donald Trump’s tweet account before he assumes duty as the president of the United States. The data looks like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(tidyverse)</code></pre></div>
<pre><code>## Loading required package: tidyverse</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──</code></pre>
<pre><code>## ✔ ggplot2 3.2.1     ✔ purrr   0.3.3
## ✔ tibble  2.1.3     ✔ dplyr   0.8.3
## ✔ tidyr   1.0.0     ✔ stringr 1.4.0
## ✔ readr   1.3.1     ✔ forcats 0.4.0</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(quanteda)</code></pre></div>
<pre><code>## Loading required package: quanteda</code></pre>
<pre><code>## Package version: 1.9.9007</code></pre>
<pre><code>## Parallel computing: 2 of 4 threads used.</code></pre>
<pre><code>## See https://quanteda.io for tutorials and examples.</code></pre>
<pre><code>## 
## Attaching package: &#39;quanteda&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:utils&#39;:
## 
##     View</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(rio)</code></pre></div>
<pre><code>## Loading required package: rio</code></pre>
<pre><code>## 
## Attaching package: &#39;rio&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:quanteda&#39;:
## 
##     convert</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trump_tweets &lt;-<span class="st"> </span><span class="kw">import</span>(<span class="st">&#39;./data/trump.json&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span>as_tibble
trump_tweets</code></pre></div>
<pre><code>## # A tibble: 17,936 x 7
##    source  text       created_at  retweet_count favorite_count is_retweet id_str
##    &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;               &lt;int&gt;          &lt;int&gt; &lt;lgl&gt;      &lt;chr&gt; 
##  1 Twitte… Heads of … Mon Dec 31…         20519          74566 FALSE      10798…
##  2 Twitte… ....Senat… Mon Dec 31…         17027          63013 FALSE      10798…
##  3 Twitte… It’s incr… Mon Dec 31…         29355         125931 FALSE      10797…
##  4 Twitte… I’m in th… Mon Dec 31…         30742         131151 FALSE      10797…
##  5 Twitte… I’m in th… Mon Dec 31…          1123           4217 FALSE      10797…
##  6 Twitte… I am the … Mon Dec 31…         25252         111582 FALSE      10797…
##  7 Twitte… I campaig… Mon Dec 31…         21960          90883 FALSE      10797…
##  8 Twitte… .....Exce… Mon Dec 31…         15081          72353 FALSE      10797…
##  9 Twitte… ...I camp… Mon Dec 31…         22000         100819 FALSE      10797…
## 10 Twitte… If anybod… Mon Dec 31…         17379          79095 FALSE      10797…
## # … with 17,926 more rows</code></pre>
<p>Up to this point, you might notice this book uses tidyverse—or more precisely, dplyr—for data manipulation. Yes. If you are not familar with dplyr, it is a good idea for you to read the book R4DS (available online). The book you are reading now is not an introduction to dplyr. But as a refresher, let me show you all the dplyr you will need to deal with 80% of the situations. You probably only need to know 5 <em>verbs</em> and then combine them together. You may call these 6 verbs “Big Six” if you like.</p>
</div>
<div id="an-express-summary-of-tidyverse" class="section level2">
<h2><span class="header-section-number">3.2</span> An express summary of tidyverse</h2>
<p>The first verb is <strong>select</strong>. It is used to select particular column(s) from a data frame. By the way, our data is a <strong>tibble</strong>, an arguably nicer version of data frame. Suppose we want to select only the columns source and text.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trump_tweets <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(source, text)</code></pre></div>
<pre><code>## # A tibble: 17,936 x 2
##    source           text                                                        
##    &lt;chr&gt;            &lt;chr&gt;                                                       
##  1 Twitter for iPh… Heads of countries are calling wanting to know why Senator …
##  2 Twitter for iPh… ....Senator Schumer, more than a year longer than any other…
##  3 Twitter for iPh… It’s incredible how Democrats can all use their ridiculous …
##  4 Twitter for iPh… I’m in the Oval Office. Democrats, come back from vacation …
##  5 Twitter for iPh… I’m in the Oval Office. Democrats, come back from vacation …
##  6 Twitter for iPh… I am the only person in America who could say that, “I’m br…
##  7 Twitter for iPh… I campaigned on Border Security, which you cannot have with…
##  8 Twitter for iPh… .....Except the results are FAR BETTER than I ever said the…
##  9 Twitter for iPh… ...I campaigned on getting out of Syria and other places. N…
## 10 Twitter for iPh… If anybody but Donald Trump did what I did in Syria, which …
## # … with 17,926 more rows</code></pre>
<p>The second verb is <strong>filter</strong>. It is used to filter rows from a tibble based on certain criteria. Suppose you want to get all the rows which were tweeted from an Android phone.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trump_tweets <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(source, <span class="st">&quot;Android&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(source, text)</code></pre></div>
<pre><code>## # A tibble: 7,302 x 2
##    source           text                                                        
##    &lt;chr&gt;            &lt;chr&gt;                                                       
##  1 Twitter for And… &quot;Watch @JudgeJeanine on @FoxNews tonight at 9:00 P.M.&quot;      
##  2 Twitter for And… &quot;ObamaCare will explode and we will all get together and pi…
##  3 Twitter for And… &quot;LinkedIn Workforce Report: January and February were the s…
##  4 Twitter for And… &quot;Don&#39;t let the FAKE NEWS tell you that there is big infight…
##  5 Twitter for And… &quot;I am working on a new system where there will be competiti…
##  6 Twitter for And… &quot;Don&#39;t worry, getting rid of state lines, which will promot…
##  7 Twitter for And… &quot;For eight years Russia \&quot;ran over\&quot; President Obama, got s…
##  8 Twitter for And… &quot;Our wonderful new Healthcare Bill is now out for review an…
##  9 Twitter for And… &quot;122 vicious prisoners, released by the Obama Administratio…
## 10 Twitter for And… &quot;Who was it that secretly said to Russian President, \&quot;Tell…
## # … with 7,292 more rows</code></pre>
<p>In the above example, we combine two verbs (<em>filter</em> and <em>select</em>) using the pipe (%&gt;%) operator. Some might disagree, but this method is more elegant. If you can tell a story using your dplyr code, it is probably a good code. For example, you can tell a story using the above code as such: We have our <em>trump_tweets</em> data, <strong>and then</strong> we <em>filter</em> all tweets where <em>source</em> contains “Android”, <strong>and then</strong> we <em>select</em> only the <em>source</em> and <em>text</em> columns.</p>
<p>So, the pipe operators in the above code are corresponding to all “and then” in the story.</p>
<p>From the above story, you might notice that the <em>source</em> column is recording from which device the tweet was tweeted, e.g. Android.</p>
<p>It is a good idea to see what are the other variants of “source” in our data. The next verb that we need to know is <strong>group_by</strong>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trump_tweets <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(source)</code></pre></div>
<pre><code>## # A tibble: 17,936 x 7
## # Groups:   source [16]
##    source  text       created_at  retweet_count favorite_count is_retweet id_str
##    &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;               &lt;int&gt;          &lt;int&gt; &lt;lgl&gt;      &lt;chr&gt; 
##  1 Twitte… Heads of … Mon Dec 31…         20519          74566 FALSE      10798…
##  2 Twitte… ....Senat… Mon Dec 31…         17027          63013 FALSE      10798…
##  3 Twitte… It’s incr… Mon Dec 31…         29355         125931 FALSE      10797…
##  4 Twitte… I’m in th… Mon Dec 31…         30742         131151 FALSE      10797…
##  5 Twitte… I’m in th… Mon Dec 31…          1123           4217 FALSE      10797…
##  6 Twitte… I am the … Mon Dec 31…         25252         111582 FALSE      10797…
##  7 Twitte… I campaig… Mon Dec 31…         21960          90883 FALSE      10797…
##  8 Twitte… .....Exce… Mon Dec 31…         15081          72353 FALSE      10797…
##  9 Twitte… ...I camp… Mon Dec 31…         22000         100819 FALSE      10797…
## 10 Twitte… If anybod… Mon Dec 31…         17379          79095 FALSE      10797…
## # … with 17,926 more rows</code></pre>
<p>It seems that we have done nothing here. But you might notice the output says “Groups: source [16]”. <em>group_by</em> works the best when it is combined with <strong>summarise</strong>. dplyr is smart enough to accept both British and American spellings. So you can use <em>summarize</em> if you want.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> We use <em>summarise</em> to generate one-element summary of your data. For example, you want to get the total number of rows of this data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trump_tweets <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">ntweets =</span> <span class="kw">n</span>())</code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   ntweets
##     &lt;int&gt;
## 1   17936</code></pre>
<p>Using the above code, we can tell a story as such: We have our <em>trump_tweets</em> data, and then we want to summarise our data as <em>ntweets</em> whereas ntweets equals to n(), i.e. number of rows. Let’s try to use this verb with <em>group_by</em>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trump_tweets <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(source) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">ntweets =</span> <span class="kw">n</span>())</code></pre></div>
<pre><code>## # A tibble: 16 x 2
##    source                   ntweets
##    &lt;chr&gt;                      &lt;int&gt;
##  1 Facebook                       2
##  2 Instagram                     70
##  3 Media Studio                 156
##  4 Mobile Web (M5)                2
##  5 Neatly For BlackBerry 10       5
##  6 Periscope                      7
##  7 TweetDeck                      2
##  8 Twitter Ads                   97
##  9 Twitter for Android         7302
## 10 Twitter for BlackBerry        94
## 11 Twitter for iPad              59
## 12 Twitter for iPhone          7965
## 13 Twitter Media Studio          12
## 14 Twitter Mirror for iPad        1
## 15 Twitter QandA                 10
## 16 Twitter Web Client          2152</code></pre>
<p>The story of the above code is: We have our <em>trump_tweets</em> … probably I can skip this part now, and then we group our data by <em>source</em> and then we summarise our data as <em>ntweets</em> whereas ntweets equals to n(), i.e. number of rows. So, what <em>group_by</em> does, is to split the data into groups by a certain column (or columns). The subsequent steps are then became group-based analysis. This principle is called “Split-Apply-Combine strategy” by <span class="citation">Wickham (<a href="#ref-wickham2011">2011</a>)</span>.</p>
<p>this group-based analysis shows that there are many variants! In this analysis, we keep only those tweets from iPhone and Android only. So, which verb we should use? I give you 10 seconds to think.</p>
<p>Well…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trump_tweets <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(source, <span class="st">&quot;Android|iPhone&quot;</span>))</code></pre></div>
<pre><code>## # A tibble: 15,267 x 7
##    source  text       created_at  retweet_count favorite_count is_retweet id_str
##    &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;               &lt;int&gt;          &lt;int&gt; &lt;lgl&gt;      &lt;chr&gt; 
##  1 Twitte… Heads of … Mon Dec 31…         20519          74566 FALSE      10798…
##  2 Twitte… ....Senat… Mon Dec 31…         17027          63013 FALSE      10798…
##  3 Twitte… It’s incr… Mon Dec 31…         29355         125931 FALSE      10797…
##  4 Twitte… I’m in th… Mon Dec 31…         30742         131151 FALSE      10797…
##  5 Twitte… I’m in th… Mon Dec 31…          1123           4217 FALSE      10797…
##  6 Twitte… I am the … Mon Dec 31…         25252         111582 FALSE      10797…
##  7 Twitte… I campaig… Mon Dec 31…         21960          90883 FALSE      10797…
##  8 Twitte… .....Exce… Mon Dec 31…         15081          72353 FALSE      10797…
##  9 Twitte… ...I camp… Mon Dec 31…         22000         100819 FALSE      10797…
## 10 Twitte… If anybod… Mon Dec 31…         17379          79095 FALSE      10797…
## # … with 15,257 more rows</code></pre>
<p><strong>mutate</strong> is for creating new columns.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trump_tweets <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(source, <span class="st">&quot;Android|iPhone&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">android =</span> <span class="kw">str_detect</span>(source, <span class="st">&quot;Android&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(android, text)</code></pre></div>
<pre><code>## # A tibble: 15,267 x 2
##    android text                                                                 
##    &lt;lgl&gt;   &lt;chr&gt;                                                                
##  1 FALSE   Heads of countries are calling wanting to know why Senator Schumer i…
##  2 FALSE   ....Senator Schumer, more than a year longer than any other Administ…
##  3 FALSE   It’s incredible how Democrats can all use their ridiculous sound bit…
##  4 FALSE   I’m in the Oval Office. Democrats, come back from vacation now and g…
##  5 FALSE   I’m in the Oval Office. Democrats, come back from vacation now and g…
##  6 FALSE   I am the only person in America who could say that, “I’m bringing ou…
##  7 FALSE   I campaigned on Border Security, which you cannot have without a str…
##  8 FALSE   .....Except the results are FAR BETTER than I ever said they were go…
##  9 FALSE   ...I campaigned on getting out of Syria and other places. Now when I…
## 10 FALSE   If anybody but Donald Trump did what I did in Syria, which was an IS…
## # … with 15,257 more rows</code></pre>
<p>Last but not least, <strong>arrange</strong> is for sorting.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trump_tweets <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(source, <span class="st">&quot;Android|iPhone&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">android =</span> <span class="kw">str_detect</span>(source, <span class="st">&quot;Android&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(android, text) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(android)</code></pre></div>
<pre><code>## # A tibble: 15,267 x 2
##    android text                                                                 
##    &lt;lgl&gt;   &lt;chr&gt;                                                                
##  1 FALSE   Heads of countries are calling wanting to know why Senator Schumer i…
##  2 FALSE   ....Senator Schumer, more than a year longer than any other Administ…
##  3 FALSE   It’s incredible how Democrats can all use their ridiculous sound bit…
##  4 FALSE   I’m in the Oval Office. Democrats, come back from vacation now and g…
##  5 FALSE   I’m in the Oval Office. Democrats, come back from vacation now and g…
##  6 FALSE   I am the only person in America who could say that, “I’m bringing ou…
##  7 FALSE   I campaigned on Border Security, which you cannot have without a str…
##  8 FALSE   .....Except the results are FAR BETTER than I ever said they were go…
##  9 FALSE   ...I campaigned on getting out of Syria and other places. Now when I…
## 10 FALSE   If anybody but Donald Trump did what I did in Syria, which was an IS…
## # … with 15,257 more rows</code></pre>
<p>It seems that it did nothing. We can set it to arrange by descending order. So that the tweets from Android are on top.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trump_tweets <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(source, <span class="st">&quot;Android|iPhone&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">android =</span> <span class="kw">str_detect</span>(source, <span class="st">&quot;Android&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(android, text) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(android))</code></pre></div>
<pre><code>## # A tibble: 15,267 x 2
##    android text                                                                 
##    &lt;lgl&gt;   &lt;chr&gt;                                                                
##  1 TRUE    &quot;Watch @JudgeJeanine on @FoxNews tonight at 9:00 P.M.&quot;               
##  2 TRUE    &quot;ObamaCare will explode and we will all get together and piece toget…
##  3 TRUE    &quot;LinkedIn Workforce Report: January and February were the strongest …
##  4 TRUE    &quot;Don&#39;t let the FAKE NEWS tell you that there is big infighting in th…
##  5 TRUE    &quot;I am working on a new system where there will be competition in the…
##  6 TRUE    &quot;Don&#39;t worry, getting rid of state lines, which will promote competi…
##  7 TRUE    &quot;For eight years Russia \&quot;ran over\&quot; President Obama, got stronger a…
##  8 TRUE    &quot;Our wonderful new Healthcare Bill is now out for review and negotia…
##  9 TRUE    &quot;122 vicious prisoners, released by the Obama Administration from Gi…
## 10 TRUE    &quot;Who was it that secretly said to Russian President, \&quot;Tell Vladimir…
## # … with 15,257 more rows</code></pre>
<p>Oh, yea! We have our data! So we should do our sentiment analysis now, right?</p>
<p><strong>NO!</strong> Nein! Non! いいえ! 唔係!</p>
</div>
<div id="creating-ground-truth-data" class="section level2">
<h2><span class="header-section-number">3.3</span> Creating ground truth data</h2>
<p>This is another split-path between data scientists and automated content analysts.</p>
<p>If you know nothing about automated content analysis, the traditional way of dealing with our data is to manually <strong>code</strong> all tweets. The word “code” as a verb can create confusion here, because it can also mean “programming.”<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> In this programming-heavy book, I am going to use another verb for “coding” (in the social sciences’ sense): data categorizing. I believe this term can still capture most, but not all, nuances of the verb “coding” (in the social sciences’ sense). For the verb “coding” in the programming’s sense, I am going to use, as you can guess, programming.</p>
<p>Sorry for the detour. Traditionally, social scientists approach this problem by catagorizing the unstructured data into a form suitable for computer analysis. A tweet is a bunch of characters that a (naive) computer cannot extract meanings—or semantics—out of it. However, whether or not a tweet is positive is a semantic problem. Homo sapiens have a brain and some of us have the knowledge in English to determine the semantics of a piece of text. We need to tell the computer, what semantically is expressed in a tweet. This procedure is called data categorization.</p>
<p>In an academic setting, it usually means the principal investigator of this project (i.e. you) would assemble a team of student assistants to categorize all tweets by reading them one by one and then asserting every one of them if they are positive or not. In order to ensure interrater reliability, we usually assign at least two student assistants to read one tweet.</p>
<p>This procedure of data categorization is notoriously expensive. In Germany, for instance, one needs to pay a student assistant €15.8 per hour in 2020. Let’s assume a student assistant can read 4 tweets per minute. In order to read every single tweets (n = 15,267) by two students, it takes (15,267 x 2) / 4 = 7,633.5 man-minutes or 127.2 man-hours. Therefore, the principal investigator (i.e you) needs to pay €2009.76 just for the data categorization. It is not a handsome amount of money: You can buy 4464 packs of instant ramen that you can eat for about a year. But remember, now you are not doing this for your PhD thesis. It is just an exercise of a stupid book. If you are willing to pay this: “Danke schön!”, your student assistants say. If you are not willing to pay this, what should you do?</p>
<p>Instead of asking your student assistants to categorize all data, we can use a computer to categorize the data. But as I said previously, a (naive) computer cannot extract semantics from a piece of text. However, it can extract an approximated version of semantics —or a proxy measure— from text content.</p>
<p>how about we just ask them to code some of them? As an excercise, let’s say a random sample of 30 tweets?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trump_tweets <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sample_n</span>(<span class="dv">30</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(text)</code></pre></div>
<pre><code>## # A tibble: 30 x 1
##    text                                                                         
##    &lt;chr&gt;                                                                        
##  1 &quot;\&quot;@ScoodieGolden Twitter loves Trump. 1000&#39;s of retweets for Mr. Trump whil…
##  2 &quot;The FAKE NEWS media (failing @nytimes, @NBCNews, @ABC, @CBS, @CNN) is not m…
##  3 &quot;Women defy media narrative, love Trump at packed Michigan rally.\nVIDEO: ht…
##  4 &quot;Uncomfortable looking NBC reporter Willie Geist calls me to ask for favors …
##  5 &quot;The new Fake News narrative is that there is CHAOS in the White House. Wron…
##  6 &quot;The \&quot;deplorables\&quot; came back to haunt Hillary.They expressed their feeling…
##  7 &quot;Ivanka Trump will be interviewed on @foxandfriends.&quot;                        
##  8 &quot;Denzel Washington gave a wonderful commencement speech over the weekend. Fr…
##  9 &quot;Crooked Hillary&#39;s bad judgement forced her to announce that she would go to…
## 10 &quot;\&quot;@StephanieKrista: @realDonaldTrump THANK-YOU!!! I hope you are running fo…
## # … with 20 more rows</code></pre>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-liang2017">
<p>Liang, Hai, and Jonathan JH Zhu. 2017. “Big Data, Collection of (Social Media, Harvesting).” <em>The International Encyclopedia of Communication Research Methods</em>. Wiley Online Library, 1–18. doi:<a href="https://doi.org/10.1002/9781118901731.iecrm0015">10.1002/9781118901731.iecrm0015</a>.</p>
</div>
<div id="ref-munzert2014">
<p>Munzert, Simon, Christian Rubba, Peter Meißner, and Dominic Nyhuis. 2014. <em>Automated Data Collection with R: A Practical Guide to Web Scraping and Text Mining</em>. John Wiley &amp; Sons.</p>
</div>
<div id="ref-wickham2011">
<p>Wickham, Hadley. 2011. “The Split-Apply-Combine Strategy for Data Analysis.” <em>Journal of Statistical Software</em> 40 (1). Citeseer: 1–29. doi:<a href="https://doi.org/10.18637/jss.v040.i01">10.18637/jss.v040.i01</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>The author of this book admits that he is not an expert in communication theories.<a href="the-whole-game.html#fnref1">↩</a></p></li>
<li id="fn2"><p>This code should be replaced with <strong>count()</strong>, but for the sake of education, let’s bear with me with a combination of <em>group_by</em> and <em>summarise</em><a href="the-whole-game.html#fnref2">↩</a></p></li>
<li id="fn3"><p>Probably social scientists used the word “code” as a verb earlier than programmers. This is a problem of English. German has two different verbs: kodieren and coden.<a href="the-whole-game.html#fnref3">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="what-is-automated-content-analysis.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["automatedcontentanalysis.pdf", "automatedcontentanalysis.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
