# What is Content analysis

In the previous chapter, we have gone through together in a whole game approach a typical scenario of automated content analysis. 

In this chapter, we are going to go back to the theorectical foundation of automated content analysis. Unless the adjective before an objective functions is a negation, one should expect an object with an adjective should still belong to the category of that object. For example, a flying cat is still a cat. A liberal, popular, male dictator is still a dictator. However, fake news is not news, because 'fake' functions as a negation. 

Based on this logic, in the previous chapter I have made a proclaimation that automated content analysis is still content analysis. It is similar to the fact that quantative content analysis is still content analysis. This seems to be a reasonable expectation, but one cannot always assume these long compound nouns created by researchers always have this simple, logical property. For example, thematic meta-analysis is not meta-analysis, eventhough 'thematic' does not function as a negation. ^[The reason for it is that the term was incorrectly coined. The coining this term has not carefully considered the original definition of meta-analysis.]

So, what is automated content analysis all about? It is better for us to go back to the basic form: What is content analysis?

### Definitions

In the realm of content analysis, there are two bibles, so to speak. They are *"Content Analysis: An Introduction to Its Methodology"* by Klaus Krippendorff and *"The Content Analysis Guidebook"* by Kimberley A. Neuendorf. Except the fact that both books are written by communication researcher, both books give a very similar definition of content analysis. 

Krippendorff defines content analysis as follow:

---

**Content analysis is a research technique for making replicable and valid inferences from text (or other meaningful matter) to the context of their use.**

---

Neuendorf defines content analysis as follow:

---

**Content analysis is a summarizing, quantitative analysis of messages that relies on the scientific method (including attention to objectivity-intersubjectivity, a priori design, reliability, validity, generalizability, replicability, and hypothesis testing) and is not limited as to the types of variables that may be measured or the context in which the message are created or presented.**

---

Both definitions emphasize the scientific aspect of the technique. Neuendorf has a six-part definition of content analysis as a scientific method, which explains each of the six elements inside the parenthesis of her definition. Once again, all six elements define how content analysis is a scientific method. In this discussion, I focus only on four important elements: a priori design, hypothesis testing, reliability and validity. These four elements are important for our discussion of automated content analysis and can draw distinctions between automated content analysis and other forms of text analysis, e.g. text mining. In the following two subsection, the four elements are discussed in the following two subsections: Principle and measurement.

#### The principle of (automated) content analysis

##### An a priori Design

A content analysis should have an *a priori* (i.e. "before the fact") design. Therefore, the research questions, hypotheses and operationalization of variables must be available before the text data were collected. A valid content analysis should be no room for researchers to play with the data and then choose the variables or even the hypotheses they want to study, thereby makes any content analysis be confirmatory, not exploratory. Thus, any exploratory work should not be labeled as an (automated) content analysis. This draws a major distinct between (automated) content analysis and other text analytic approaches such as text mining, "big data" or data science. 

Data science, as defined in @wickham2016 , is a circular process of "transform" (coding / data manipulation), "visualize" (data visualization) and "model" (data modeling). This repeated circular procedure -- for instance, it is possible to go back from an analytic step of data modling back to coding, is not compatible with the strict *a priori* requirement of (automated) content analysis. (Automated) content analysis must be a linear process. In Neuendorf's book, she derive a flowchart of content analysis. ^[This flowchart is also [available online](https://academic.csuohio.edu/neuendorf_ka/content/flowchart.html)] In that flowchart, there is no split-path and the linear process consists of nine steps: theory and rationale, conceptualization decisions, operationalization measures, creation of coding schemes, sampling, training and initial reliability, coding, and, final reliability and tabulation and reporting. If (automated) content analysis is content analysis, it should follow the same linear process. There is only a slight difference in the assessment of reliability (next subsection).



#### Hypothesis testing

A content analysis as a scientific method should be "hypothetico-deductive". Therefore, an (automated) content analysis must have one or more theory driven hypotheses to be tested deductively. These hypotheses describe an anticipated prediction.  Research question can also be derived in a priori, if the existing theory is enough to support an anticipated prediction. Because of that, an (automated) content analysis must have an "a priori design" (the previous point). An exploratory analysis, such as text mining or data science approaches, is for hypothesis generation.



#### The measurement in (automated) content analysis

##### Reliability

##### Validity



## What gets automated?

What the current literature says about ACA.

## Best practices

* Validation

* Contrasting Confirmatory / exploratory

* Methodological transparency

